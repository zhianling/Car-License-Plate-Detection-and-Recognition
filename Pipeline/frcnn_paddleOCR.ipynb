{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# FRCNN + PaddleOCR (Inference)",
   "id": "883fd79fd381a835"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Import Dependencies",
   "id": "4b3a1a80c8189868"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-11T09:31:08.241934Z",
     "start_time": "2025-05-11T09:31:06.355821Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import paddle\n",
    "from paddleocr import PaddleOCR\n",
    "import cv2\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ],
   "id": "932042637fc8f7f9",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Configuration",
   "id": "5cd02dce6644dc2"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-11T09:31:08.318743Z",
     "start_time": "2025-05-11T09:31:08.289428Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Cell id: 6ab5a433226c0e38 (MODIFIED)\n",
    "# --- Configuration for Detection ---\n",
    "CUSTOM_MODEL_CLASS_NAMES = ['__background__', 'carplate']\n",
    "TARGET_CLASS_NAME = \"carplate\"\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "CONFIDENCE_THRESHOLD = 0.5\n",
    "BOX_COLOR = (0, 0, 255)       # Red for FRCNN car plates\n",
    "TEXT_COLOR = (255, 255, 255)  # White for FRCNN label\n",
    "TEXT_BG_COLOR = (0, 0, 0)     # Black for FRCNN label background\n",
    "\n",
    "OCR_TEXT_COLOR = (0, 255, 0)      # Green for PaddleOCR text\n",
    "OCR_TEXT_BG_COLOR = (0, 0, 0)     # Black background for PaddleOCR text\n",
    "\n",
    "try:\n",
    "    TARGET_CLASS_ID = CUSTOM_MODEL_CLASS_NAMES.index(TARGET_CLASS_NAME.lower())\n",
    "    print(f\"Targeting class '{TARGET_CLASS_NAME}' with ID: {TARGET_CLASS_ID} from {CUSTOM_MODEL_CLASS_NAMES}\")\n",
    "except ValueError:\n",
    "    print(f\"Error: Target class '{TARGET_CLASS_NAME}' not found in CUSTOM_MODEL_CLASS_NAMES: {CUSTOM_MODEL_CLASS_NAMES}\")\n",
    "    TARGET_CLASS_ID = None\n",
    "\n",
    "# --- Get Video Path  ---\n",
    "video_path = \"../data/video/58.mp4\"  # Or your desired video\n",
    "if video_path == '0':\n",
    "    video_source = 0 # Use webcam\n",
    "else:\n",
    "    video_source = video_path"
   ],
   "id": "6ab5a433226c0e38",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Targeting class 'carplate' with ID: 1 from ['__background__', 'carplate']\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Load FRCNN",
   "id": "5f00c74d330f337c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-11T09:31:08.835406Z",
     "start_time": "2025-05-11T09:31:08.335930Z"
    }
   },
   "cell_type": "code",
   "source": [
    "nun_classes = 2\n",
    "frcnn = torchvision.models.detection.fasterrcnn_resnet50_fpn(pretrained=False, num_classes=nun_classes)\n",
    "frcnn.load_state_dict(torch.load('../models/full_fasterrcnn_best.pth', map_location= 'cuda')['model_state_dict'])\n",
    "frcnn.to('cuda')\n",
    "frcnn.eval()"
   ],
   "id": "aa0d29a4e8c1f6fb",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FasterRCNN(\n",
       "  (transform): GeneralizedRCNNTransform(\n",
       "      Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
       "      Resize(min_size=(800,), max_size=1333, mode='bilinear')\n",
       "  )\n",
       "  (backbone): BackboneWithFPN(\n",
       "    (body): IntermediateLayerGetter(\n",
       "      (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "      (bn1): FrozenBatchNorm2d(64, eps=1e-05)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "      (layer1): Sequential(\n",
       "        (0): Bottleneck(\n",
       "          (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(64, eps=1e-05)\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(64, eps=1e-05)\n",
       "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(256, eps=1e-05)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): FrozenBatchNorm2d(256, eps=1e-05)\n",
       "          )\n",
       "        )\n",
       "        (1): Bottleneck(\n",
       "          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(64, eps=1e-05)\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(64, eps=1e-05)\n",
       "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(256, eps=1e-05)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (2): Bottleneck(\n",
       "          (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(64, eps=1e-05)\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(64, eps=1e-05)\n",
       "          (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(256, eps=1e-05)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (layer2): Sequential(\n",
       "        (0): Bottleneck(\n",
       "          (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(128, eps=1e-05)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(128, eps=1e-05)\n",
       "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(512, eps=1e-05)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "            (1): FrozenBatchNorm2d(512, eps=1e-05)\n",
       "          )\n",
       "        )\n",
       "        (1): Bottleneck(\n",
       "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(128, eps=1e-05)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(128, eps=1e-05)\n",
       "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(512, eps=1e-05)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (2): Bottleneck(\n",
       "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(128, eps=1e-05)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(128, eps=1e-05)\n",
       "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(512, eps=1e-05)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (3): Bottleneck(\n",
       "          (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(128, eps=1e-05)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(128, eps=1e-05)\n",
       "          (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(512, eps=1e-05)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (layer3): Sequential(\n",
       "        (0): Bottleneck(\n",
       "          (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(256, eps=1e-05)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(256, eps=1e-05)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(1024, eps=1e-05)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "            (1): FrozenBatchNorm2d(1024, eps=1e-05)\n",
       "          )\n",
       "        )\n",
       "        (1): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(256, eps=1e-05)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(256, eps=1e-05)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(1024, eps=1e-05)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (2): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(256, eps=1e-05)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(256, eps=1e-05)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(1024, eps=1e-05)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (3): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(256, eps=1e-05)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(256, eps=1e-05)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(1024, eps=1e-05)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (4): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(256, eps=1e-05)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(256, eps=1e-05)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(1024, eps=1e-05)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (5): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(256, eps=1e-05)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(256, eps=1e-05)\n",
       "          (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(1024, eps=1e-05)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (layer4): Sequential(\n",
       "        (0): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(512, eps=1e-05)\n",
       "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(512, eps=1e-05)\n",
       "          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(2048, eps=1e-05)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "            (1): FrozenBatchNorm2d(2048, eps=1e-05)\n",
       "          )\n",
       "        )\n",
       "        (1): Bottleneck(\n",
       "          (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(512, eps=1e-05)\n",
       "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(512, eps=1e-05)\n",
       "          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(2048, eps=1e-05)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (2): Bottleneck(\n",
       "          (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): FrozenBatchNorm2d(512, eps=1e-05)\n",
       "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): FrozenBatchNorm2d(512, eps=1e-05)\n",
       "          (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): FrozenBatchNorm2d(2048, eps=1e-05)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (fpn): FeaturePyramidNetwork(\n",
       "      (inner_blocks): ModuleList(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (1): Conv2dNormActivation(\n",
       "          (0): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (2): Conv2dNormActivation(\n",
       "          (0): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (3): Conv2dNormActivation(\n",
       "          (0): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (layer_blocks): ModuleList(\n",
       "        (0-3): 4 x Conv2dNormActivation(\n",
       "          (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "      )\n",
       "      (extra_blocks): LastLevelMaxPool()\n",
       "    )\n",
       "  )\n",
       "  (rpn): RegionProposalNetwork(\n",
       "    (anchor_generator): AnchorGenerator()\n",
       "    (head): RPNHead(\n",
       "      (conv): Sequential(\n",
       "        (0): Conv2dNormActivation(\n",
       "          (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (cls_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (bbox_pred): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))\n",
       "    )\n",
       "  )\n",
       "  (roi_heads): RoIHeads(\n",
       "    (box_roi_pool): MultiScaleRoIAlign(featmap_names=['0', '1', '2', '3'], output_size=(7, 7), sampling_ratio=2)\n",
       "    (box_head): TwoMLPHead(\n",
       "      (fc6): Linear(in_features=12544, out_features=1024, bias=True)\n",
       "      (fc7): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "    )\n",
       "    (box_predictor): FastRCNNPredictor(\n",
       "      (cls_score): Linear(in_features=1024, out_features=2, bias=True)\n",
       "      (bbox_pred): Linear(in_features=1024, out_features=8, bias=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Load PaddleOCR\n",
   "id": "5ebedeb5812d28d6"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-11T09:31:09.865231Z",
     "start_time": "2025-05-11T09:31:08.851416Z"
    }
   },
   "cell_type": "code",
   "source": [
    "gpu_available  = paddle.device.is_compiled_with_cuda()\n",
    "print(gpu_available)"
   ],
   "id": "7a96645c7926fa95",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-11T09:31:15.410680Z",
     "start_time": "2025-05-11T09:31:09.869233Z"
    }
   },
   "cell_type": "code",
   "source": [
    "paddleocr = PaddleOCR(\n",
    "    use_angle_cls = True,\n",
    "    lang = 'en',\n",
    "    use_gpu = True\n",
    ")"
   ],
   "id": "22732913b0293ff7",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025/05/11 17:31:10] ppocr DEBUG: Namespace(alpha=1.0, alphacolor=(255, 255, 255), benchmark=False, beta=1.0, binarize=False, cls_batch_num=6, cls_image_shape='3, 48, 192', cls_model_dir='C:\\\\Users\\\\User/.paddleocr/whl\\\\cls\\\\ch_ppocr_mobile_v2.0_cls_infer', cls_thresh=0.9, cpu_threads=10, crop_res_save_dir='./output', det=True, det_algorithm='DB', det_box_type='quad', det_db_box_thresh=0.6, det_db_score_mode='fast', det_db_thresh=0.3, det_db_unclip_ratio=1.5, det_east_cover_thresh=0.1, det_east_nms_thresh=0.2, det_east_score_thresh=0.8, det_limit_side_len=960, det_limit_type='max', det_model_dir='C:\\\\Users\\\\User/.paddleocr/whl\\\\det\\\\en\\\\en_PP-OCRv3_det_infer', det_pse_box_thresh=0.85, det_pse_min_area=16, det_pse_scale=1, det_pse_thresh=0, det_sast_nms_thresh=0.2, det_sast_score_thresh=0.5, draw_img_save_dir='./inference_results', drop_score=0.5, e2e_algorithm='PGNet', e2e_char_dict_path='./ppocr/utils/ic15_dict.txt', e2e_limit_side_len=768, e2e_limit_type='max', e2e_model_dir=None, e2e_pgnet_mode='fast', e2e_pgnet_score_thresh=0.5, e2e_pgnet_valid_set='totaltext', enable_mkldnn=False, formula=False, formula_algorithm='LaTeXOCR', formula_batch_num=1, formula_char_dict_path=None, formula_model_dir=None, fourier_degree=5, gpu_id=0, gpu_mem=500, help='==SUPPRESS==', image_dir=None, image_orientation=False, invert=False, ir_optim=True, kie_algorithm='LayoutXLM', label_list=['0', '180'], lang='en', layout=True, layout_dict_path=None, layout_model_dir=None, layout_nms_threshold=0.5, layout_score_threshold=0.5, max_batch_size=10, max_text_length=25, merge_no_span_structure=True, min_subgraph_size=15, mode='structure', ocr=True, ocr_order_method=None, ocr_version='PP-OCRv4', onnx_providers=False, onnx_sess_options=False, output='./output', page_num=0, precision='fp32', process_id=0, re_model_dir=None, rec=True, rec_algorithm='SVTR_LCNet', rec_batch_num=6, rec_char_dict_path='C:\\\\Users\\\\User\\\\miniconda3\\\\envs\\\\car-plate-ocr\\\\lib\\\\site-packages\\\\paddleocr\\\\ppocr\\\\utils\\\\en_dict.txt', rec_image_inverse=True, rec_image_shape='3, 48, 320', rec_model_dir='C:\\\\Users\\\\User/.paddleocr/whl\\\\rec\\\\en\\\\en_PP-OCRv4_rec_infer', recovery=False, recovery_to_markdown=False, return_word_box=False, save_crop_res=False, save_log_path='./log_output/', savefile=False, scales=[8, 16, 32], ser_dict_path='../train_data/XFUND/class_list_xfun.txt', ser_model_dir=None, show_log=True, sr_batch_num=1, sr_image_shape='3, 32, 128', sr_model_dir=None, structure_version='PP-StructureV2', table=True, table_algorithm='TableAttn', table_char_dict_path=None, table_max_len=488, table_model_dir=None, total_process_num=1, type='ocr', use_angle_cls=True, use_dilation=False, use_gcu=False, use_gpu=True, use_mlu=False, use_mp=False, use_npu=False, use_onnx=False, use_pdf2docx_api=False, use_pdserving=False, use_space_char=True, use_tensorrt=False, use_visual_backbone=True, use_xpu=False, vis_font_path='./doc/fonts/simfang.ttf', warmup=False)\n",
      "[2025/05/11 17:31:10] ppocr WARNING: The first GPU is used for inference by default, GPU ID: 0\n",
      "[2025/05/11 17:31:12] ppocr WARNING: The first GPU is used for inference by default, GPU ID: 0\n",
      "[2025/05/11 17:31:14] ppocr WARNING: The first GPU is used for inference by default, GPU ID: 0\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Draw Predictions (Object Detection & OCR)",
   "id": "8de7310642c1c066"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-11T09:31:47.936738Z",
     "start_time": "2025-05-11T09:31:15.473807Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Cell id: dc8b44f4dc5661a3 (NEW CONTENT)\n",
    "\n",
    "# --- Video Capture ---\n",
    "cap = cv2.VideoCapture(video_source)\n",
    "\n",
    "if not cap.isOpened():\n",
    "    print(f\"Error: Could not open video source '{video_source}'. Please check the path or camera.\")\n",
    "    # In a notebook, avoid exit(), just print and let the cell finish.\n",
    "else:\n",
    "    print(f\"Processing video: {video_source} with FRCNN and PaddleOCR\")\n",
    "    window_title = f\"Car Plate FRCNN Detection & PaddleOCR\"\n",
    "    cv2.namedWindow(window_title, cv2.WINDOW_NORMAL) # Allows resizing\n",
    "\n",
    "    frame_count = 0\n",
    "    while cap.isOpened():\n",
    "        ret, frame_bgr = cap.read()\n",
    "\n",
    "        if not ret:\n",
    "            if isinstance(video_source, str):\n",
    "                print(\"End of video file reached.\")\n",
    "            else:\n",
    "                print(\"Error reading frame from webcam.\")\n",
    "            break\n",
    "\n",
    "        frame_to_draw = frame_bgr.copy()\n",
    "        frame_count += 1\n",
    "\n",
    "        # --- FRCNN Preprocessing ---\n",
    "        img_rgb_frcnn = cv2.cvtColor(frame_bgr, cv2.COLOR_BGR2RGB)\n",
    "        # For torchvision models, image needs to be [C, H, W] and normalized\n",
    "        # Standard transform for ResNet50 based FasterRCNN\n",
    "        frcnn_transform = torchvision.transforms.Compose([\n",
    "            torchvision.transforms.ToTensor(), # Converts to [0,1] range and C,H,W\n",
    "            # torchvision.transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]) # Usually part of model.transform\n",
    "        ])\n",
    "        # Your FRCNN model's transform might handle normalization.\n",
    "        # If you've loaded it with weights, it typically has a .transform attribute.\n",
    "        # For simplicity, if your model already includes normalization in its internal transform:\n",
    "        img_tensor_frcnn = torch.from_numpy(img_rgb_frcnn.transpose((2, 0, 1))).float().to(device) / 255.0\n",
    "        # If normalization is not part of model.transform, use this:\n",
    "        # img_tensor_frcnn = frcnn_transform(img_rgb_frcnn).to(device)\n",
    "\n",
    "\n",
    "        # --- FRCNN Inference ---\n",
    "        with torch.no_grad():\n",
    "            frcnn_outputs = frcnn([img_tensor_frcnn]) # frcnn is your FRCNN model\n",
    "\n",
    "        predictions = frcnn_outputs[0]\n",
    "        pred_boxes = predictions['boxes'].cpu().numpy()\n",
    "        pred_labels = predictions['labels'].cpu().numpy()\n",
    "        pred_scores = predictions['scores'].cpu().numpy()\n",
    "\n",
    "        # --- Process Detections and Perform OCR ---\n",
    "        num_detections_in_frame = 0\n",
    "        if TARGET_CLASS_ID is not None:\n",
    "            for i in range(len(pred_scores)):\n",
    "                score = pred_scores[i]\n",
    "                label_id = pred_labels[i]\n",
    "                box = pred_boxes[i]\n",
    "\n",
    "                if label_id == TARGET_CLASS_ID and score >= CONFIDENCE_THRESHOLD:\n",
    "                    num_detections_in_frame += 1\n",
    "                    xmin, ymin, xmax, ymax = map(int, box)\n",
    "\n",
    "                    # Clamp coordinates to be within frame boundaries\n",
    "                    xmin = max(0, xmin)\n",
    "                    ymin = max(0, ymin)\n",
    "                    xmax = min(frame_bgr.shape[1], xmax)\n",
    "                    ymax = min(frame_bgr.shape[0], ymax)\n",
    "\n",
    "                    # Draw FRCNN bounding box\n",
    "                    cv2.rectangle(frame_to_draw, (xmin, ymin), (xmax, ymax), BOX_COLOR, 2)\n",
    "                    class_name_to_display = CUSTOM_MODEL_CLASS_NAMES[label_id]\n",
    "                    label_text_frcnn = f\"{class_name_to_display}: {score:.2f}\"\n",
    "\n",
    "                    (text_w_frcnn, text_h_frcnn), base_frcnn = cv2.getTextSize(label_text_frcnn, cv2.FONT_HERSHEY_SIMPLEX, 0.6, 1)\n",
    "                    cv2.rectangle(frame_to_draw, (xmin, ymin - text_h_frcnn - base_frcnn - 2), (xmin + text_w_frcnn, ymin - base_frcnn + 2), TEXT_BG_COLOR, -1)\n",
    "                    cv2.putText(frame_to_draw, label_text_frcnn, (xmin, ymin - base_frcnn -1),\n",
    "                                cv2.FONT_HERSHEY_SIMPLEX, 0.6, TEXT_COLOR, 1, cv2.LINE_AA)\n",
    "\n",
    "                    # --- PaddleOCR: Crop the plate and read text ---\n",
    "                    if xmax > xmin and ymax > ymin: # Check if the box is valid\n",
    "                        plate_roi_bgr = frame_bgr[ymin:ymax, xmin:xmax] # Crop from original BGR\n",
    "\n",
    "                        try:\n",
    "                            # Perform OCR on the cropped plate using PaddleOCR\n",
    "                            # For a single ROI, we expect text recognition only\n",
    "                            # The 'paddleocr' instance is from your setup cell\n",
    "                            ocr_result = paddleocr.ocr(plate_roi_bgr, det=False, rec=True, cls=paddleocr.use_angle_cls)\n",
    "\n",
    "                            recognized_text = \"\"\n",
    "                            text_confidence = 0.0\n",
    "\n",
    "                            if ocr_result and ocr_result[0]:\n",
    "                                lines = ocr_result[0]\n",
    "                                if lines: # If lines is not None or empty\n",
    "                                    # Assuming the first recognized line is the primary one for a plate\n",
    "                                    recognized_text_tuple = lines[0] # This should be (text_string, confidence)\n",
    "                                    recognized_text = recognized_text_tuple[0]\n",
    "                                    text_confidence = recognized_text_tuple[1]\n",
    "\n",
    "                                    # Optional: Filter or clean the recognized text\n",
    "                                    recognized_text = ''.join(filter(str.isalnum, recognized_text)).upper()\n",
    "\n",
    "\n",
    "                            if recognized_text:\n",
    "                                ocr_display_text = f\"{recognized_text} ({text_confidence:.2f})\"\n",
    "                                ocr_text_y_pos = ymax + 20 # Position below the FRCNN box\n",
    "                                if ocr_text_y_pos + 10 > frame_to_draw.shape[0]: # If too low, put above\n",
    "                                    ocr_text_y_pos = ymin - 10\n",
    "\n",
    "                                (text_w_ocr, text_h_ocr), base_ocr = cv2.getTextSize(ocr_display_text, cv2.FONT_HERSHEY_SIMPLEX, 0.7, 2)\n",
    "                                cv2.rectangle(frame_to_draw, (xmin, ocr_text_y_pos - text_h_ocr - base_ocr),\n",
    "                                              (xmin + text_w_ocr, ocr_text_y_pos + base_ocr),\n",
    "                                              OCR_TEXT_BG_COLOR, -1)\n",
    "                                cv2.putText(frame_to_draw, ocr_display_text, (xmin, ocr_text_y_pos),\n",
    "                                            cv2.FONT_HERSHEY_SIMPLEX, 0.7, OCR_TEXT_COLOR, 2)\n",
    "                                if frame_count % 10 == 0:\n",
    "                                    print(f\"Frame {frame_count}: FRCNN Plate (Score: {score:.2f}), PaddleOCR: '{recognized_text}' (Conf: {text_confidence:.2f})\")\n",
    "                        except Exception as e:\n",
    "                            if frame_count % 10 == 0:\n",
    "                                print(f\"Frame {frame_count}: Error during PaddleOCR for a plate ROI: {e}\")\n",
    "\n",
    "\n",
    "        if frame_count % 30 == 0:\n",
    "            print(f\"Frame {frame_count}: Found {num_detections_in_frame} '{TARGET_CLASS_NAME}' instances by FRCNN.\")\n",
    "\n",
    "        cv2.imshow(window_title, frame_to_draw)\n",
    "\n",
    "        key = cv2.waitKey(1) & 0xFF\n",
    "        if key == ord('q'):\n",
    "            print(\"Exiting...\")\n",
    "            break\n",
    "\n",
    "    # --- Cleanup ---\n",
    "    if cap.isOpened():\n",
    "        cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    print(\"Video processing finished and resources released.\")"
   ],
   "id": "dc8b44f4dc5661a3",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing video: data/video/58.mp4 with FRCNN and PaddleOCR\n",
      "Frame 30: FRCNN Plate (Score: 0.88), PaddleOCR: 'OLA9206' (Conf: 0.33)\n",
      "Frame 30: Found 1 'carplate' instances by FRCNN.\n",
      "Frame 60: Found 0 'carplate' instances by FRCNN.\n",
      "Frame 80: FRCNN Plate (Score: 0.51), PaddleOCR: 'DA53' (Conf: 0.72)\n",
      "Frame 90: Found 0 'carplate' instances by FRCNN.\n",
      "Frame 120: FRCNN Plate (Score: 0.93), PaddleOCR: 'MUT9' (Conf: 0.60)\n",
      "Frame 120: Found 1 'carplate' instances by FRCNN.\n",
      "Frame 140: FRCNN Plate (Score: 0.84), PaddleOCR: 'UUS2' (Conf: 0.20)\n",
      "Frame 150: Found 0 'carplate' instances by FRCNN.\n",
      "Frame 160: FRCNN Plate (Score: 0.85), PaddleOCR: 'DISESH' (Conf: 0.51)\n",
      "Frame 160: FRCNN Plate (Score: 0.51), PaddleOCR: 'AS' (Conf: 0.46)\n",
      "Frame 180: Found 0 'carplate' instances by FRCNN.\n",
      "Frame 190: FRCNN Plate (Score: 0.96), PaddleOCR: '08230' (Conf: 0.51)\n",
      "Frame 190: FRCNN Plate (Score: 0.73), PaddleOCR: 'DABEE' (Conf: 0.68)\n",
      "Frame 210: Found 0 'carplate' instances by FRCNN.\n",
      "Frame 240: Found 0 'carplate' instances by FRCNN.\n",
      "Frame 260: FRCNN Plate (Score: 0.52), PaddleOCR: 'LOXIG' (Conf: 0.39)\n",
      "Frame 270: FRCNN Plate (Score: 0.80), PaddleOCR: '006' (Conf: 0.35)\n",
      "Frame 270: FRCNN Plate (Score: 0.59), PaddleOCR: 'A166' (Conf: 0.43)\n",
      "Frame 270: Found 2 'carplate' instances by FRCNN.\n",
      "Frame 280: FRCNN Plate (Score: 0.82), PaddleOCR: 'BUST' (Conf: 0.34)\n",
      "Frame 300: Found 0 'carplate' instances by FRCNN.\n",
      "Frame 310: FRCNN Plate (Score: 0.64), PaddleOCR: 'UR62' (Conf: 0.40)\n",
      "Frame 320: FRCNN Plate (Score: 0.56), PaddleOCR: 'C035628' (Conf: 0.47)\n",
      "Frame 330: FRCNN Plate (Score: 0.61), PaddleOCR: '3040' (Conf: 0.31)\n",
      "Frame 330: Found 1 'carplate' instances by FRCNN.\n",
      "Frame 350: FRCNN Plate (Score: 0.76), PaddleOCR: '1OPL342' (Conf: 0.56)\n",
      "Frame 360: FRCNN Plate (Score: 0.51), PaddleOCR: '042' (Conf: 0.38)\n",
      "Frame 360: Found 1 'carplate' instances by FRCNN.\n",
      "Frame 370: FRCNN Plate (Score: 0.87), PaddleOCR: 'E19680' (Conf: 0.62)\n",
      "Frame 390: Found 0 'carplate' instances by FRCNN.\n",
      "Frame 420: Found 0 'carplate' instances by FRCNN.\n",
      "Frame 450: FRCNN Plate (Score: 0.59), PaddleOCR: 'CASSL' (Conf: 0.58)\n",
      "Frame 450: Found 1 'carplate' instances by FRCNN.\n",
      "Frame 460: FRCNN Plate (Score: 0.60), PaddleOCR: 'SW86' (Conf: 0.63)\n",
      "Frame 470: FRCNN Plate (Score: 0.67), PaddleOCR: 'VT' (Conf: 0.40)\n",
      "Frame 480: FRCNN Plate (Score: 0.68), PaddleOCR: '10982A' (Conf: 0.48)\n",
      "Frame 480: Found 1 'carplate' instances by FRCNN.\n",
      "Frame 500: FRCNN Plate (Score: 0.87), PaddleOCR: 'U' (Conf: 0.18)\n",
      "Frame 500: FRCNN Plate (Score: 0.53), PaddleOCR: 'A' (Conf: 0.19)\n",
      "Frame 500: FRCNN Plate (Score: 0.50), PaddleOCR: 'M' (Conf: 0.18)\n",
      "Frame 510: Found 0 'carplate' instances by FRCNN.\n",
      "Frame 520: FRCNN Plate (Score: 0.94), PaddleOCR: 'DMS5T' (Conf: 0.39)\n",
      "Frame 520: FRCNN Plate (Score: 0.54), PaddleOCR: 'PEE' (Conf: 0.16)\n",
      "Frame 530: FRCNN Plate (Score: 0.55), PaddleOCR: 'BASEO' (Conf: 0.54)\n",
      "Frame 540: Found 0 'carplate' instances by FRCNN.\n",
      "Frame 560: FRCNN Plate (Score: 0.65), PaddleOCR: '08308' (Conf: 0.54)\n",
      "Exiting...\n",
      "Video processing finished and resources released.\n"
     ]
    }
   ],
   "execution_count": 6
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
